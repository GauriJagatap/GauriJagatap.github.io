---
title: "How interpretable is data?"
layout: post
date: 2017-05-05 19:48
image: /assets/images/markdown.jpg
headerImage: false
tag:
- machine learning
- data science
category: blog
author: gaurijagatap
description: Markdown summary with different options
# jemoji: '<img class="emoji" title=":ramen:" alt=":ramen:" src="https://assets.github.com/images/icons/emoji/unicode/1f35c.png" height="20" width="20" align="absmiddle">'
mathjax: true
---


I happened to have two course projects that I only recently wrapped up, and they turned out to be somewhat related! The two topics being sparse principal component analysis (SPCA) and non-negative matrix factorization (NMF). Both of them, key tools to help interpret data better.

So wait. Given a set of data points, can’t we as humans do the intelligible task of interpretation? What do these data-interpretations tools do that we can’t?
$x$ = $y$

$$
 |\psi_1\|
$$

\begin{equation}
    |\psi_1\|
\end{equation}

